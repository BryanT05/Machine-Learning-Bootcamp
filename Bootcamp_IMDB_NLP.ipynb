{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootcamp IMDB NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24918f00e7244bc5a328298f0cd6b01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02976f4684d6470fb82688dde63ef989",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_664a30c6b28448ac832f247d337512c4",
              "IPY_MODEL_702702c888104e1ea6a7792a38cd520b"
            ]
          }
        },
        "02976f4684d6470fb82688dde63ef989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "664a30c6b28448ac832f247d337512c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ef1252819c447fb97db95cd073ee2f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c1bcb518d9e46039128961cc5298539"
          }
        },
        "702702c888104e1ea6a7792a38cd520b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eaf706cbccd44f079ff105a89dea070c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:01&lt;00:00, 146kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ce90ddf2bd04d2fa3492d1e74469513"
          }
        },
        "8ef1252819c447fb97db95cd073ee2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c1bcb518d9e46039128961cc5298539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaf706cbccd44f079ff105a89dea070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ce90ddf2bd04d2fa3492d1e74469513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fe485466723440aa85de267651a0805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0dc8dea568794df0b98626e47e24aa11",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7422a89cf1b477e9dee5500418d5bf7",
              "IPY_MODEL_d51a697478394bd3bbcfa4611bc74521"
            ]
          }
        },
        "0dc8dea568794df0b98626e47e24aa11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7422a89cf1b477e9dee5500418d5bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89e594298e884f48848aa676ccadc088",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2f816150ff649b28034ea71dae58536"
          }
        },
        "d51a697478394bd3bbcfa4611bc74521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_111bf4c09f6f4f0f9bf18bba5b7d127f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 495B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b47f916cd664e8499f555e2afa53b7e"
          }
        },
        "89e594298e884f48848aa676ccadc088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2f816150ff649b28034ea71dae58536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "111bf4c09f6f4f0f9bf18bba5b7d127f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b47f916cd664e8499f555e2afa53b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af525f2207ab4b538d06b9c74ab4f63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_018e75eefcd147a295b8fa91e2625902",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_912943e363344c88bf3599280cbb69b4",
              "IPY_MODEL_0f8590126a5f4627ad2506c5f61057a3"
            ]
          }
        },
        "018e75eefcd147a295b8fa91e2625902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "912943e363344c88bf3599280cbb69b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cec99e0d0e214d12900a62469573370b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d8ee6f1f3844e7ba90cf2028e24d406"
          }
        },
        "0f8590126a5f4627ad2506c5f61057a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_140b78de495b427eb52cd6f83090b33a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 2.74MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4c90963e7af4cc6b87ad7d2f9d895bd"
          }
        },
        "cec99e0d0e214d12900a62469573370b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d8ee6f1f3844e7ba90cf2028e24d406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "140b78de495b427eb52cd6f83090b33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4c90963e7af4cc6b87ad7d2f9d895bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baca8bd194bd4440988d11ad1caba870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_efe68be02caf458fa78194a085e7d388",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1707fee178942acba560308b91f2fbb",
              "IPY_MODEL_a18f542b515549e0b3732215fee23d12"
            ]
          }
        },
        "efe68be02caf458fa78194a085e7d388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1707fee178942acba560308b91f2fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df097ee5850a497690b0fb0c156e9088",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c66a54d2b084992b04ce2e5c01c689e"
          }
        },
        "a18f542b515549e0b3732215fee23d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f535d1ccfb0b44db9efc528faa7bcd56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 10.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa6d0f07255f4f1facd34b935df341e2"
          }
        },
        "df097ee5850a497690b0fb0c156e9088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c66a54d2b084992b04ce2e5c01c689e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f535d1ccfb0b44db9efc528faa7bcd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa6d0f07255f4f1facd34b935df341e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM7eaI5zI-lw"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fm3wVMYJC0T",
        "outputId": "273a01d8-a46f-4564-fa6f-fea3e655fe3d"
      },
      "source": [
        "# https://huggingface.co/transformers/\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNpc2_SnJKpp"
      },
      "source": [
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# HuggingFace NLP library\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSDhKipZJ8Sa"
      },
      "source": [
        "## Check TensorFlow and GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rhs864EIJ9sN",
        "outputId": "68768c54-916d-4e60-f85f-3a108eb9de7b"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS9CjY1vKAOn",
        "outputId": "88e2d72a-6de8-4580-f0ea-26fc786bae5f"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ-LhBBCKWbL"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av32UV47KYSe"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/BryanT05/Machine-Learning-Bootcamp/main/IMDB%20Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "30ulf_hoMwnt",
        "outputId": "ee404c42-2cfc-4b5e-e4a2-003982f93f46"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DH937A_MZ1D",
        "outputId": "3dcc69a0-b283-4f75-d6a1-9e654eb4e0c6"
      },
      "source": [
        "df['review']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        One of the other reviewers has mentioned that ...\n",
              "1        A wonderful little production. <br /><br />The...\n",
              "2        I thought this was a wonderful way to spend ti...\n",
              "3        Basically there's a family where a little boy ...\n",
              "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
              "                               ...                        \n",
              "49995    I thought this movie did a down right good job...\n",
              "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
              "49997    I am a Catholic taught in parochial elementary...\n",
              "49998    I'm going to have to disagree with the previou...\n",
              "49999    No one expects the Star Trek movies to be high...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rNqwHasM4Oq",
        "outputId": "5c976a1c-43ca-4134-e568-ed1ec54e78e3"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiaTP_UZNFxQ",
        "outputId": "68ba628d-8390-4889-90d3-697904e7eae8"
      },
      "source": [
        "df['sentiment'] = df['sentiment'].astype('category').cat.codes\n",
        "df['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyBabxY6M62K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Q3YClbNnM6",
        "outputId": "0919e156-e8b8-4ab4-eb40-4f0a4b835417"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n",
            "(10000,)\n",
            "(40000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6vCaL5xNtYl",
        "outputId": "f3e8d734-f5ea-41a1-bd1f-34a1584cb909"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    20000\n",
              "0    20000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUGE61UONv5R",
        "outputId": "80934aa0-25b9-4c59-f272-ce9f26d496fc"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5000\n",
              "0    5000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuJkRuEZPbaK"
      },
      "source": [
        "train = pd.DataFrame({'text': X_train, 'label': y_train})\n",
        "test = pd.DataFrame({'text': X_test, 'label': y_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaph9IdpPye_"
      },
      "source": [
        "train.to_csv('IMDB_train.csv', index=False)\n",
        "test.to_csv('IMDB_test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS8hIpg5P6oR"
      },
      "source": [
        "## Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx2gCoWeP-M9"
      },
      "source": [
        "TRAIN_FILE_PATH = 'IMDB_train.csv'\n",
        "TEST_FILE_PATH = 'IMDB_test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqdGJPuWQEIs"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset\n",
        "\n",
        "# kolum 1 string, kolum 2 integer\n",
        "ds_train = tf.data.experimental.CsvDataset([TRAIN_FILE_PATH],\n",
        "                                           record_defaults=[tf.constant([\"\"], dtype=tf.string), tf.constant([0], dtype=tf.int64)],\n",
        "                                           header=True)\n",
        "\n",
        "ds_test = tf.data.experimental.CsvDataset([TEST_FILE_PATH],\n",
        "                                           record_defaults=[tf.constant([\"\"], dtype=tf.string), tf.constant([0], dtype=tf.int64)],\n",
        "                                           header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tS0_efRThG"
      },
      "source": [
        "CLASSES = ['Negative', 'Positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8bEhHknSNbe",
        "outputId": "ff8be56a-4f3b-4c8d-8dda-6c26e69be436"
      },
      "source": [
        "for message, label in ds_train.take(5):\n",
        "    print(message, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'I caught this little gem totally by accident back in 1980 or \\'81. I was at a revival theatre to see two old silly sci-fi movies. The theatre was packed full and (with no warning) they showed a bunch of sci-fi short spoofs (to get us in the mood). Most were somewhat amusing but THIS came on and, within seconds, the audience was in hysterics! The biggest laugh came when they showed \"Princess Laia\" having huge cinnamon buns instead of hair on her head. She looks at the camera, gives a grim smile and nods. That made it even funnier! You gotta see \"Chewabacca\" played by what looks like a Muppet! It was extremely silly and stupid...but I couldn\\'t stop laughing. Most of the dialogue was drowned out because of all the laughter. Also if you know \"Star Wars\" pretty well it\\'s even funnier--they deliberately poke fun at some of the dialogue. This REALLY works with an audience! A definite 10!', shape=(), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(b'I can\\'t believe that I let myself into this movie to accomplish a favor my friends ask me early this April 14, 2007. This movie certainly a pain in your ass in theater and sickly boring, I haven\\'t even felt the gory impact of its \"daunting scenes\" which I deem to be complete failure to attract its audience. The worst even trampled me, cause my friend failed to come on time at the theater because she was busy assisting her boyfriend in looking for an appropriate lodge to stay in for one night. I wasn\\'t really disappointed with that matter, but this movie is a matter indeed for me, poor plot, useless storyline, naively created and I don\\'t know what to say anymore.<br /><br />The title doesn\\'t suggest anyway the creeps and horror it failed to overture us viewers, maybe the beating of the animals could get more the creeps if they show it in theaters the real situational play. Good luck to anyone who attempts to watch it anyway.', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"*spoiler alert!* it just gets to me the nerve some people have to remake (and i use the term loosely here..) good movies. in the american version of this dutch thriller, someone decided the original ending wasn't pasteurized enough for american audiences. so what do they do? they create a new one! a stupid, improbable, i-pretend-i'm-dead-but-come-to-life-again-so-the-good-guy-can-kick-my-butt- some-more kind of ending. do yourself a favor and get the original one.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"If there's one thing I've learnt from watching George Romero's Creepshow, it's that if you stumble upon an mysterious old crate that someone has obviously gone to a lot of effort to hide, just leave well alone: there's probably something nasty inside.<br /><br />Obviously, Professor Gordon Crowley, Robert Englund's character in 'Jack Brooks, Monster Slayer' isn't a Romero fan, 'cos he busts open the old wooden box he finds buried in his yard, only to discover\\xc2\\x97surprise, surprise\\xc2\\x97an ancient demon that possesses his body (initially causing him to eat and vomit rather a lot).<br /><br />When the demon eventually erupts from Crowley's body during chemistry class and begins to transform the students into hellish, flesh-tearing beasts, it's up to plumber Jack Brooks (Trevor Matthews) to try and stop the foul creatures, armed only with a length of pipe and fuelled by a lifelong hatred of all things monstrous!.<br /><br />The DVD packaging for Jon Knautz's low-budget monster flick promises one hell of a fun ride, offering cheesy thrills and spills of the kind one might expect from your average 80s creature feature (toothy critters, rubber monster suits, gruesome gore, and absolutely no CGI!)\\xc2\\x97and for the last 15 minutes, that's exactly what viewers get: non-stop splattery effects; a silly, tentacled Jabba-style demon thingy; and mucho macho monster mashing!<br /><br />It's a shame, then, that the rest of the film's running time\\xc2\\x97a massive 70 minutes or so\\xc2\\x97is mostly spent following Jack as he goes about his boring, everyday business: plumbing, visiting his shrink, going to chemistry class, and upsetting his girlfriend. If you think you might enjoy a film that focuses primarily on coping with childhood trauma and anger management, buying spare boiler valves from a hardware shop, and the chemical properties of Sodium, then this is the film for you; but if it's a massive dose of monster mayhem you're after, then I'd advise looking elsewhere!\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b'I remember when this was in theaters, reviews said it was horrible. Well, I didn\\'t think it was that bad. It was amusing and had a lot of tongue-in-cheek humor concerning families around holiday time.<br /><br />Ben Affleck is a rich guy who needs to find a family for Christmas to please his girlfriend. He goes to visit the house he grew up in and strikes a deal to rent the family there for Christmas. I really liked the lawyer scene where they sign a contract. That was funny.<br /><br />So, he makes silly requests of the family and even writes scripts for them to read. Of course, the family has a hot daughter for the love interest. And he learns that the holidays aren\\'t so bad after all.<br /><br />Also, the whole doo-dah act was funny, especially when they replaced the first one with a black guy, and the girlfriends\\'s parents didn\\'t even say anything about it. And the parts where doo-dah is hitting on his \"supposed daughter.\" FINAL VERDICT: I thought it\\'s worth checking out if you catch it on cable.', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0DXIaLHSOkn",
        "outputId": "9860db58-7c0a-4301-88f7-81b489dffd69"
      },
      "source": [
        "for message, label in ds_test.take(5):\n",
        "    print(message, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'Yes, MTV there really is a way to market Daria. What started as a clever teenage angst-\"comment on everything that sucks and make the viewer feel better about their sucky teenage life\" sitcom now mutated into a \"how you should deal with your problems\"-charade. I used to watch Daria all the time and loved it. Now, sitting here after watching the so called \"movie\" I can only wonder what the point of this all was. Daria tells us how to lead out life in college? Excuse me? didn\\'t the point Daria made every episode that what you like to do is ok, as long as it is ok with yourself no matter what the rest of the sick sad world thinks of it? This entire thing reminded me of the scene in \"Reality Bites\" the movie channel shows the documentry for the first time.', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"The story of the bride fair is an amusing and engaging one, and it is to the filmmaker's credit that he sets out to portray rural Minnesotans with the same respect ordinarily reserved for Coast-dwellers. It is weird, though, to find an independent movie, the brainchild of a single person, that is as unambitious and clich\\xc3\\xa9-ridden as a committee-brewed Hollywood potboiler.<br /><br />The portrait of rural people is intended to be affectionate, I think, but these characters don't ring true to me--I have had quite a few meals in small-town diners, but never overheard a debate on the merits of different nineteenth-century English novelists. One might suggest that writer/director Semans has no more experience with rural culture than the Coen brothers, and considerably less satiric verve.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"A team varied between Scully and Mulder, two other scientists, a pilot, and the guy who plays Bana on Seinfeld, go up to an Arctic research post where all members have died off by either killing each other or killing themselves. They discover there's a worm- a virus- that is parasitic to the point of madness and death. The problem is, after a certain dog lashes out, anyone could be infected, but who? This is not just my favorite episode of season 1, but also one of my favorites from the show. The Arctic environment encloses the characters and, of course like Carpenter's the Thing, it's a lot of fun watching these even-tempered characters suddenly start to flip out in dramatic scenes. And the visual effects of the worm and its effects under the skin are cheesy, I didn't mind them at all. The drama between the characters ends up working more than it would usually because of the tension and because all of the actors (including the Bana guy) understand what's going on in the story. And, as usual, I loved the ambiguity of the ending. Highly recommended.\", shape=(), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(b'This was a popular movie probably because of the humor in it, the fast-moving story, an underdog character who shuts up all the loudmouths, etc. Funny thing is, you probably couldn\\'t make a movie with this title if you substituted anybody but \"white\" as anything else would be deemed racist by the PC police. <br /><br />Nonetheless, Woody Harrleson as the white guy who turns out to be as good if not better than any of the black basketball players, is interesting as is his main counterpart Wesley Snipes.<br /><br />Snipes had a lot of funny put-down lines, providing much of the humor. The bad part of the film - which doesn\\'t bother a lot of people - is the extreme profanity in here and the sleaziness of all the characters. That includes Woody\\'s girlfriend, played by Rosie Perez. There are no really clean, nice people in this movie. For that reason, I can\\'t honestly recommend the film, at least not to friends or those who are offended by a lotof profanity', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"This movie made me so angry!! Here I am thinking that here's a new horror movie, one w/a sense of intelligence & then the movie starts. The scenery, the delivery of lines, the costumes, the fake gore, must I go on? There are porno movies out with better dialog than this. I understand the concept behind indie movies, but my goodness, this wasn't just indie this was a high school book report shot w/a camcorder & the cast are all friends & relatives. This is 1 movie that was doomed from its beginning. Maybe if it was 1982 instead of the new millennium this movie could fly. But it seems to me that someone hung a rock around this albatross's neck & it was sinking at a constant rate of speed.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oN1Xw6nSQVT"
      },
      "source": [
        "## What happened during BERT?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRy0zhjIST50"
      },
      "source": [
        "example_sentence = 'it is so bad. how could the movie with 5 star rating be like that.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-FEWKQyTbpK"
      },
      "source": [
        "# https://aclanthology.org/2020.aacl-main.85.pdf\n",
        "MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuorwRM7VrDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "24918f00e7244bc5a328298f0cd6b01c",
            "02976f4684d6470fb82688dde63ef989",
            "664a30c6b28448ac832f247d337512c4",
            "702702c888104e1ea6a7792a38cd520b",
            "8ef1252819c447fb97db95cd073ee2f8",
            "3c1bcb518d9e46039128961cc5298539",
            "eaf706cbccd44f079ff105a89dea070c",
            "6ce90ddf2bd04d2fa3492d1e74469513",
            "2fe485466723440aa85de267651a0805",
            "0dc8dea568794df0b98626e47e24aa11",
            "f7422a89cf1b477e9dee5500418d5bf7",
            "d51a697478394bd3bbcfa4611bc74521",
            "89e594298e884f48848aa676ccadc088",
            "e2f816150ff649b28034ea71dae58536",
            "111bf4c09f6f4f0f9bf18bba5b7d127f",
            "4b47f916cd664e8499f555e2afa53b7e",
            "af525f2207ab4b538d06b9c74ab4f63d",
            "018e75eefcd147a295b8fa91e2625902",
            "912943e363344c88bf3599280cbb69b4",
            "0f8590126a5f4627ad2506c5f61057a3",
            "cec99e0d0e214d12900a62469573370b",
            "3d8ee6f1f3844e7ba90cf2028e24d406",
            "140b78de495b427eb52cd6f83090b33a",
            "f4c90963e7af4cc6b87ad7d2f9d895bd",
            "baca8bd194bd4440988d11ad1caba870",
            "efe68be02caf458fa78194a085e7d388",
            "c1707fee178942acba560308b91f2fbb",
            "a18f542b515549e0b3732215fee23d12",
            "df097ee5850a497690b0fb0c156e9088",
            "5c66a54d2b084992b04ce2e5c01c689e",
            "f535d1ccfb0b44db9efc528faa7bcd56",
            "aa6d0f07255f4f1facd34b935df341e2"
          ]
        },
        "outputId": "e0826e46-112c-4b76-d04a-f3d8966cb97a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24918f00e7244bc5a328298f0cd6b01c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fe485466723440aa85de267651a0805",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af525f2207ab4b538d06b9c74ab4f63d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baca8bd194bd4440988d11ad1caba870",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf6CDgA_WDW8",
        "outputId": "b898234d-d855-4fc2-979a-3fa5e01793f0"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXUG5UkV_xv"
      },
      "source": [
        "## Part 1: Add Special Token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53DMxwEjWH7c"
      },
      "source": [
        "Kita harus menambah token khusus ke kalimat kita. Token khusus ini adalah `[CLS]` dan `[SEP]`.\n",
        "\n",
        "- [CLS] stands for **classification**. It is added at the beginning because the training tasks here is sentence classification. And because they need an input that can represent the meaning of the entire sentence, they introduce a new tag.\n",
        "- [SEP] The **separator** token, which is used when building a sequence from multiple sequences, e.g. two sequences for sequence classification or for a text and a question for question answering. It is also used as the last token of a sequence built with special tokens.\n",
        "\n",
        "Example:\n",
        "- single sequence: [CLS] X [SEP]\n",
        "- pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RLLsUtwWHTw",
        "outputId": "5d880dba-0045-4546-bac9-18821fa8268c"
      },
      "source": [
        "example_sentence_with_special_tokens = '[CLS]' + example_sentence + '[SEP]'\n",
        "tokenized_sentence = tokenizer.tokenize(example_sentence_with_special_tokens)\n",
        "tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'it',\n",
              " 'is',\n",
              " 'so',\n",
              " 'bad',\n",
              " '.',\n",
              " 'how',\n",
              " 'could',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'with',\n",
              " '5',\n",
              " 'star',\n",
              " 'rating',\n",
              " 'be',\n",
              " 'like',\n",
              " 'that',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQQjNBNYO87"
      },
      "source": [
        "## Part 2: Convert Token to Token ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9bmS_RyYRhy",
        "outputId": "2f09e7b2-d469-4089-98c0-655ba2c75c60"
      },
      "source": [
        "vocabulary = tokenizer.get_vocab()\n",
        "\n",
        "print(list(vocabulary.keys())[2000:2100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['space', 'La', 'directed', 'smile', 'episode', 'hours', 'whole', '##de', '##less', 'Why', 'wouldn', 'designed', 'strong', 'training', 'changed', 'Society', 'stage', 'involved', 'hadn', 'towards', 'leading', 'police', 'eight', 'kept', 'Institute', 'study', 'largest', 'child', 'eventually', 'private', 'modern', 'Court', 'throughout', 'getting', 'originally', 'attack', '##E', 'talk', 'Great', 'longer', 'songs', 'alone', '##ine', 'wide', 'dead', 'walked', 'shot', '##ri', 'Oh', 'force', '##st', 'Art', 'today', 'friends', 'Island', 'Richard', '1989', 'center', 'construction', 'believe', 'size', 'White', 'ship', 'completed', '##B', 'gone', 'Just', 'rock', 'sat', '##R', 'radio', 'below', 'entire', 'families', 'league', 'includes', 'type', 'lived', 'official', 'range', 'hold', 'featured', 'Most', '##ter', 'president', 'passed', 'means', '##f', 'forces', 'lips', 'Mary', 'Do', 'guitar', '##ce', 'food', 'wall', 'Of', 'spent', 'Its', 'performance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5iv6r3KYhtK",
        "outputId": "92b152da-4302-4ac6-ff71-7152e2af045a"
      },
      "source": [
        "example_sentence_ids = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "print(tokenized_sentence)\n",
        "print(example_sentence_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'it', 'is', 'so', 'bad', '.', 'how', 'could', 'the', 'movie', 'with', '5', 'star', 'rating', 'be', 'like', 'that', '.', '[SEP]']\n",
            "[101, 1122, 1110, 1177, 2213, 119, 1293, 1180, 1103, 2523, 1114, 126, 2851, 5261, 1129, 1176, 1115, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI35ArkFZRq9",
        "outputId": "d49e8304-0a32-4e31-a33d-27040592f7b7"
      },
      "source": [
        "another_example = 'The movie is wonderful'\n",
        "another_example_with_special_tokens ='[CLS]' + another_example + '[SEP]'\n",
        "another_tokenized_sentence = tokenizer.tokenize(another_example_with_special_tokens)\n",
        "another_example_ids = tokenizer.convert_tokens_to_ids(another_tokenized_sentence)\n",
        "\n",
        "print(another_example)\n",
        "print(another_example_with_special_tokens)\n",
        "print(another_tokenized_sentence)\n",
        "print(another_example_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The movie is wonderful\n",
            "[CLS]The movie is wonderful[SEP]\n",
            "['[CLS]', 'The', 'movie', 'is', 'wonderful', '[SEP]']\n",
            "[101, 1109, 2523, 1110, 7310, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtfXYgOUZ_d9"
      },
      "source": [
        "## Part 3: Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMV5oTTlbfpw"
      },
      "source": [
        "MAX_LENGTH_TEST = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDRquUzZbFwc",
        "outputId": "26704d67-123e-428e-a936-b421bc611a51"
      },
      "source": [
        "len(example_sentence_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XKpqPDVbzlo",
        "outputId": "bd8af1b0-5a6e-48d4-fe7f-de6926ee3681"
      },
      "source": [
        "test_padding_length = MAX_LENGTH_TEST - len(example_sentence_ids)\n",
        "example_sentence_ids = example_sentence_ids + (test_padding_length * [0])\n",
        "example_sentence_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 1122,\n",
              " 1110,\n",
              " 1177,\n",
              " 2213,\n",
              " 119,\n",
              " 1293,\n",
              " 1180,\n",
              " 1103,\n",
              " 2523,\n",
              " 1114,\n",
              " 126,\n",
              " 2851,\n",
              " 5261,\n",
              " 1129,\n",
              " 1176,\n",
              " 1115,\n",
              " 119,\n",
              " 102,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt2q6S0_cg1J"
      },
      "source": [
        "## Part 4: Attention Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mywy3-1pdFVp"
      },
      "source": [
        "Attention mask hanya untuk token non-padded (bukan token tambahan)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2l4zBOWckfe",
        "outputId": "d64ab52a-caaf-47a7-fb38-3a1df7fdb20e"
      },
      "source": [
        "attention_mask = [1 if token > 0 else 0 for token in example_sentence_ids]\n",
        "attention_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLul_sLadhca"
      },
      "source": [
        "## Part 5: Token Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiOFDGZedjyi"
      },
      "source": [
        "Biasanya kita perlu mengurus types untuk tasks yang membutuhkan 2 kalimat sebagai input (satu kalimat kita set 0, satunya set 1). Tapi, karena kita saat ini melakukan klasifikasi, kita set 0 untuk token padded maupun non-padded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23-JqOfYdvTd",
        "outputId": "ddc460e5-d9f0-4006-b4b9-307afa0e3b1b"
      },
      "source": [
        "token_type_ids = [0] * MAX_LENGTH_TEST\n",
        "token_type_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBi2Qz6rd6vU"
      },
      "source": [
        "## Part 6: Combine All Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQwBNihCd-6R",
        "outputId": "918a3e65-5c1d-44be-a8ce-ce7eb26cdc3c"
      },
      "source": [
        "test_bert_input = {\n",
        "    'input_ids': example_sentence_ids,\n",
        "    'token_type_ids': token_type_ids,\n",
        "    'attention_mask': attention_mask\n",
        "}\n",
        "\n",
        "print(test_bert_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 1122, 1110, 1177, 2213, 119, 1293, 1180, 1103, 2523, 1114, 126, 2851, 5261, 1129, 1176, 1115, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSfJwnxWeSVI"
      },
      "source": [
        "## Shortcut 🥷"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efVFTHfYeKE3",
        "outputId": "facade2c-421f-4e33-fcb9-5a9b00ec1259"
      },
      "source": [
        "bert_input = tokenizer.encode_plus(\n",
        "    example_sentence,\n",
        "    max_length=128, # max length of the text that can go to BERT\n",
        "    add_special_tokens=True, # add special tokens\n",
        "    pad_to_max_length=True, # add [PAD] tokens\n",
        "    return_attention_mask=True, # add attention mask so model won't focus on padded tokens\n",
        "    truncation=True # truncate to a maximum length specified by max_length\n",
        ")\n",
        "\n",
        "print(bert_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 1122, 1110, 1177, 2213, 119, 1293, 1180, 1103, 2523, 1114, 126, 2851, 5261, 1129, 1176, 1115, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkTjfGfJgP3Z"
      },
      "source": [
        "## Apply Preprocessing to Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAoIgw-HgYl1"
      },
      "source": [
        "# hitung rata-rata dan panjang maksimum dari kalimat di dataset\n",
        "MAX_LENGTH = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWmWM_GXgiDQ"
      },
      "source": [
        "def convert_sentence_to_features(sentence):\n",
        "    return tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        max_length=MAX_LENGTH,\n",
        "        add_special_tokens=True,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        truncation=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9lRapULgvxd"
      },
      "source": [
        "def map_features_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'token_type_ids': token_type_ids,\n",
        "        'attention_mask': attention_masks,\n",
        "    }, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Z4mrxHhGBw"
      },
      "source": [
        "def encode_sentences(dataset):\n",
        "    input_ids_list = []\n",
        "    token_type_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    label_list = []\n",
        "\n",
        "    for message, label in tfds.as_numpy(dataset):\n",
        "        bert_input = convert_sentence_to_features(message.decode())\n",
        "        input_ids_list.append(bert_input['input_ids'])\n",
        "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "        attention_mask_list.append(bert_input['attention_mask'])\n",
        "        label_list.append([label])\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_features_to_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n03uatSRj7Z8"
      },
      "source": [
        "# Encode Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQWz12e7jwC5"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# simpan buffer 10k sample dan pilih acak dari sample tsb\n",
        "# analoginya wadah untuk simpan data\n",
        "SHUFFLE_BUFFER_SIZE = 10000 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WYa57LpkRZQ",
        "outputId": "48fdccb6-5dd2-470b-c06f-f45282eac532"
      },
      "source": [
        "ds_train_encoded = encode_sentences(ds_train).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ksUkmFr6zQB",
        "outputId": "d8335c0c-c5d1-4838-ec58-34c4c5423750"
      },
      "source": [
        "ds_test_encoded = encode_sentences(ds_test).batch(BATCH_SIZE) # test dataset engga ada efek kalau dishuffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKOhD9zC6-94",
        "outputId": "b49404cd-fb3e-45e4-e12e-79b9a6a284d2"
      },
      "source": [
        "for message, label in ds_train_encoded.take(1):\n",
        "    print(message, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
            "array([[ 101,  146, 1821, ..., 1105, 1242,  102],\n",
            "       [ 101, 2977,  112, ..., 2799, 1267,  102],\n",
            "       [ 101, 1188, 1273, ...,  140, 1818,  102],\n",
            "       ...,\n",
            "       [ 101, 3956,  117, ...,  189, 1713,  102],\n",
            "       [ 101, 1327, 2443, ..., 1106, 2869,  102],\n",
            "       [ 101, 1135,  112, ..., 1122,  117,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>} tf.Tensor(\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]], shape=(32, 1), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnNFyHxH7GZi"
      },
      "source": [
        "## Training Model 🤗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUvvX8a7OYL"
      },
      "source": [
        "- **Epochs**: 1 epoch == 1 kali membaca semua data di dataset. Analoginya 1 putaran dalam perlombaan lari. Semakin banyak putaran, semakin familiar dengan track larinya tapi makan lebih banyak waktu.\n",
        "- **Learning Rate**: learning rate adalah seberapa besar kita mengubah weights neural network. Analoginya main golf, kalau terlalu kencang bisa lewat golnya, terlalu lambat butuh beberapa kali pukulan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZcnW-3M7FUG"
      },
      "source": [
        "LEARNING_RATE = 1e-6\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_EqmwWD73pc"
      },
      "source": [
        "`TFBertForSequenceClassification`: BERT model transformer dari hugging face yang dapat digunakan dengan TF. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KEoAg_7L73CU",
        "outputId": "2f87bf9a-78c3-4369-dd10-454f4c928471"
      },
      "source": [
        "MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bert-base-cased'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPvxSy7W72oY",
        "outputId": "982ba5bd-cbd6-4428-dba4-8ec163f54c12"
      },
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # label = total kategori target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6x7dIWE8n83"
      },
      "source": [
        "## Configure Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJm_7zUm8uGG"
      },
      "source": [
        "Dengan menggunakan KERAS High-Level API, kita akan mengubah:\n",
        "- **Optimizer**: setiap kali model selesai membaca sebuah batch, algoritma optimizer digunakan untuk menyesuaikan weights di neural network. Contoh algoritma: ADAM (adaptive moment estimation).\n",
        "- **Loss**: menghitung nilai yang harus kita minimalisir ketika training.\n",
        "- **Metric**: menilai performa dari model, contoh simpel: akurasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBG6Ez5y-FIK"
      },
      "source": [
        "So, in what ways is Momentum better than vanilla gradient descent? In this comparison on the left, you can see two advantages:\n",
        "- Momentum simply moves faster (because of all the momentum it accumulates)\n",
        "- Momentum has a shot at escaping local minima (because the momentum may propel it out of a local minimum). In a similar vein, as we shall see later, it will also power through plateau regions better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GffKWcka9-vq"
      },
      "source": [
        "[link text](https://)![](https://miro.medium.com/max/800/1*zVi4ayX9u0MQQwa90CnxVg.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XVLlxPZ8j4B"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, epsilon=1e-08)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfrjUMXLBKak"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n_Y_ftcAtmo"
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVeykWmKBPa0",
        "outputId": "f5e19af7-2e1f-41d9-cad4-8981349bbc1f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJAt4W9UBajQ"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n7q16jxBjUK"
      },
      "source": [
        "TensorBoard berguna untuk menganalisa model dengan memberikan berbagai pengukuran dan visualisasi yang dibutuhkan untuk evaluasi model, mencari performance bottleneck, dll. \n",
        "\n",
        "Kita akan merekam logs di subdirektori yang memiliki timestamp, jadi kita bisa lihat visualisasi dari masing-masing run berdasarkan timestampnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7hcG5dpBW1P"
      },
      "source": [
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGT4rkdBhF-"
      },
      "source": [
        "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, profile_batch=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6WZ4TeDB2g",
        "outputId": "939ee160-dfb0-487e-e750-04b81abb92df"
      },
      "source": [
        "tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.TensorBoard at 0x7ff2d4774e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQqh5iD5B9E1"
      },
      "source": [
        "## See the power of HuggingFace! 🤗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wFs5us5CALy",
        "outputId": "7ab9e60f-a134-4b95-ea96-2b2b2f2d1ae6"
      },
      "source": [
        "history = model.fit(ds_train_encoded,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=ds_test_encoded,\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff3e186ad70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff3e186ad70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff3fca1c170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7ff3fca1c170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.7622WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1250/1250 [==============================] - 1234s 948ms/step - loss: 0.4842 - accuracy: 0.7622 - val_loss: 0.3418 - val_accuracy: 0.8536\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 1183s 946ms/step - loss: 0.3303 - accuracy: 0.8595 - val_loss: 0.3142 - val_accuracy: 0.8628\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 1182s 946ms/step - loss: 0.3023 - accuracy: 0.8732 - val_loss: 0.3005 - val_accuracy: 0.8697\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 1184s 947ms/step - loss: 0.2812 - accuracy: 0.8825 - val_loss: 0.3034 - val_accuracy: 0.8704\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 1184s 947ms/step - loss: 0.2645 - accuracy: 0.8910 - val_loss: 0.2889 - val_accuracy: 0.8735\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 1187s 949ms/step - loss: 0.2502 - accuracy: 0.8984 - val_loss: 0.2901 - val_accuracy: 0.8755\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 1185s 948ms/step - loss: 0.2337 - accuracy: 0.9066 - val_loss: 0.2964 - val_accuracy: 0.8796\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 1186s 949ms/step - loss: 0.2216 - accuracy: 0.9129 - val_loss: 0.2964 - val_accuracy: 0.8804\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 1183s 947ms/step - loss: 0.2083 - accuracy: 0.9179 - val_loss: 0.2890 - val_accuracy: 0.8822\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 1183s 947ms/step - loss: 0.1960 - accuracy: 0.9237 - val_loss: 0.3006 - val_accuracy: 0.8821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoTHxLXlCizV"
      },
      "source": [
        "## Model Evaluation Using TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvBcHYGBCLDX"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l4T9tmFD50h"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Trh5h-D7AI",
        "outputId": "d2e1b81c-ac3d-45b9-9027-2eea3d1fb0b9"
      },
      "source": [
        "_, train_acc = model.evaluate(ds_train_encoded)\n",
        "_, test_acc = model.evaluate(ds_test_encoded)\n",
        "\n",
        "print('train acc:', train_acc)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 351s 281ms/step - loss: 0.1488 - accuracy: 0.9487\n",
            "313/313 [==============================] - 87s 279ms/step - loss: 0.3006 - accuracy: 0.8821\n",
            "train acc: 0.9487000107765198\n",
            "test acc: 0.882099986076355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szlEStjTEFa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74699a91-0484-4eeb-8cff-999b3d1bd59d"
      },
      "source": [
        "y_true = []\n",
        "\n",
        "for message, label in tfds.as_numpy(ds_test):\n",
        "    y_true.append(label)\n",
        "\n",
        "y_pred = model.predict(ds_test_encoded)[0].argmax(axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfv7_cfCEEBi"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1XOOkIkGssS",
        "outputId": "1414e227-dff9-45db-cd51-82d0b4776e18"
      },
      "source": [
        "print(classification_report(y_true, y_pred, target_names=CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.89      0.88      0.88      5000\n",
            "    Positive       0.88      0.89      0.88      5000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8y5f2PiG9O8"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hFOdSXvPG-2v",
        "outputId": "ae0438bc-740c-40b5-f9bf-bae456aa5250"
      },
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=CLASSES, columns=CLASSES)\n",
        "\n",
        "hmap = sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD6XWHtJo38O"
      },
      "source": [
        "##Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gjIwnxJRAEQ",
        "outputId": "1daa6509-0b84-40a6-9e78-51e92f6c7141"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzuousUuSvUX",
        "outputId": "6be5aef4-1486-4912-e022-de119592d6a2"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Sertifikat/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Algorithm Intro.pdf'\n",
            "'Certificate NDSC Beginner _0792-0792.pdf'\n",
            "'Peserta - Webinar Save The Ocean_page-0034.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im8HyCSeUKtI",
        "outputId": "65f1573b-c1fc-451a-8bf8-6cadf9592401"
      },
      "source": [
        "model.save(\"/content/gdrive/MyDrive/Sertifikat/ModelIMDB\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Sertifikat/ModelIMDB/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Sertifikat/ModelIMDB/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdtIko18oKKR"
      },
      "source": [
        "##Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlcKEdqroPdc",
        "outputId": "9a608658-f2bf-4ac3-fd98-72fb232df95c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLJr9lRQpUsq",
        "outputId": "6d2d8eae-375e-4c10-e79b-338cd91c6a80"
      },
      "source": [
        "ls /content/gdrive/MyDrive/Sertifikat/ModelIMDB/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Algorithm Intro.pdf'\n",
            "'Certificate NDSC Beginner _0792-0792.pdf'\n",
            " \u001b[0m\u001b[01;34mIMDB.pt\u001b[0m/\n",
            " \u001b[01;34mModelIMDB\u001b[0m/\n",
            "'Peserta - Webinar Save The Ocean_page-0034.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NJadFU5oDvn"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/Sertifikat/ModelIMDB/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1104duPAp5Ka",
        "outputId": "69868758-5509-4f7a-e5da-a00b6128dc42"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Uhuzx6He65"
      },
      "source": [
        "## Create Prediction Using API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI542CsOHhUh"
      },
      "source": [
        "def predict(message):\n",
        "    input_ids_list = []\n",
        "    token_type_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    label_list = []\n",
        "\n",
        "    bert_input = convert_sentence_to_features(message)\n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append(2)\n",
        "\n",
        "    ds_predict = tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_features_to_dict)\n",
        "    print(ds_predict)\n",
        "    predicted_probs = model.predict(ds_predict)[0]\n",
        "    print(predicted_probs[0])\n",
        "    predicted_idx = predicted_probs[0].argmax(axis=-1)\n",
        "    predicted_label = CLASSES[predicted_idx]\n",
        "\n",
        "    return message, predicted_label "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8EIFQynJILcV",
        "outputId": "d1bbcdcd-7b33-425a-cefe-03af9353e646"
      },
      "source": [
        "predict(\"This movie is so bad\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ({input_ids: (128,), token_type_ids: (128,), attention_mask: (128,)}, ()), types: ({input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-307ef1ff1ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This movie is so bad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-4463bcae5a9a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_features_to_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredicted_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpredicted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py:69 return_outputs_and_add_losses\n        outputs, losses = fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py:167 wrap_with_training_arg\n        lambda: replace_training_and_call(False))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py:110 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:56 smart_cond\n        return false_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py:167 <lambda>\n        lambda: replace_training_and_call(False))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py:163 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:889 __call__\n        result = self._call(*args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:933 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:764 _initialize\n        *args, **kwds))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:3050 _get_concrete_function_internal_garbage_collected\n        graph_function, _ = self._maybe_define_function(args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:3444 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:3289 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:999 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:672 wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/function_deserialization.py:291 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (11 total):\n        * {'input_ids': <tf.Tensor 'input_ids_1:0' shape=(128, 1) dtype=int32>, 'token_type_ids': <tf.Tensor 'input_ids_2:0' shape=(128, 1) dtype=int32>, 'attention_mask': <tf.Tensor 'input_ids:0' shape=(128, 1) dtype=int32>}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 2 option(s):\n    \n    Option 1:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VfBq7D8LAGx",
        "outputId": "92ade418-32b3-430c-b167-948c1968ed70"
      },
      "source": [
        "predict(\"this is trash\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ({input_ids: (128,), token_type_ids: (128,), attention_mask: (128,)}, ()), types: ({input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>\n",
            "[0.19004142 0.28993297]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('this is trash', 'Positive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPh2Pp6MJS2V",
        "outputId": "a4539f28-64b4-4be0-8f91-7d65eeb12161"
      },
      "source": [
        "predict(df.iloc[1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.19004142 0.28993297]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.',\n",
              " 'Positive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx1Ico9kHlyk",
        "outputId": "e051fd9c-90e2-457a-fb80-61b75fb44a2a"
      },
      "source": [
        "for i in range(50):\n",
        "  predict(df.iloc[i][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n",
            "[0.19004142 0.28993297]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FzCpKRrBB_W",
        "outputId": "888a9f0f-4046-4e34-efb3-072a511952d5"
      },
      "source": [
        "print(predict('This movie is shit, everyone hates it!')[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.19004142 0.28993297]\n",
            "Positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "WurDHaUMBNnn",
        "outputId": "1a46202a-1a1f-4313-e4e8-a167dd861c2f"
      },
      "source": [
        "df.iloc[3]['review']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Jru1b6BcB2",
        "outputId": "593775a5-c3ba-4dec-fd32-6dd354fd4ac4"
      },
      "source": [
        "predict(\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.19004142 0.28993297]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\",\n",
              " 'Positive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}